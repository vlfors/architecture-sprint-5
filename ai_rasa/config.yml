language: ru
pipeline:
- name: WhitespaceTokenizer                  # Токенизатор, разделяющий текст по пробелам
- name: RegexFeaturizer                      # Извлечение признаков с помощью регулярных выражений
- name: LexicalSyntacticFeaturizer           # Лексико-синтаксический анализатор
- name: CountVectorsFeaturizer               # Извлечение признаков по частоте слов
  analyzer: "char_wb"                        # Символьные N-граммы
  min_ngram: 1
  max_ngram: 2                               # Уменьшены размеры N-грамм для ускорения
  # Подключение предобученной модели трансформера (BERT)
- name: "LanguageModelFeaturizer"
  model_name: "bert"                         # Модель BERT для русского языка
  model_weights: "bert-base-cased"           # Весы модели BERT
  cache_dir: null
- name: DIETClassifier                       # Классификатор на базе DIET
  epochs: 50                                  # Минимальное количество эпох обучения
  transformer_size: 256                       # Минимальный размер слоя трансформера
  number_of_transformer_layers: 2            # Один слой трансформера
  use_masked_language_model: false           # Отключено для ускорения
  batch_strategy: "balanced"
  hidden_layers_sizes:
    text: [256, 128]                               # Минимальные скрытые слои
- name: EntitySynonymMapper                  # Маппер синонимов сущностей
- name: ResponseSelector                     # Минимальный выбор ответа
  epochs: 20
  batch_size: [64, 128]
  learning_rate: 0.001
  hidden_layers_sizes:
    text: [256, 128]
  droprate: 0.2
  scale_loss: false
policies:
- name: MemoizationPolicy
  max_history: 5                             # Минимальная история
- name: RulePolicy
- name: TEDPolicy
  max_history: 5                             # Минимальное количество шагов в истории
  epochs: 50                                  # Минимальное количество эпох обучения
  constrain_similarities: true
assistant_id: 20250113-213246-sizzling-comment
